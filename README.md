<h1 align="center" style="color:brown;">
  üêîü•öRobot Av√≠cola V2.0
</h1>

Proyecto de la Pr√°ctica Profesional Supervisada "PPS" en Ingenier√≠a Mecatr√≥nica realizado en la FI-UNLZ.


Es un sistema rob√≥tico de 3 GDL para realizar la recolecci√≥n de huevos en nidos horizontales, tiene implementado un software de procesamiento de im√°genes para la detecci√≥n y localizaci√≥n programado en python utilizando la librer√≠a cv2 y un modelo pre-entrenado de roboflow. Se emplea un Sistema IoT para el accionamiento de control, aplicaci√≥n para el env√≠o de mensajes y recepci√≥n a trav√©s de "MQTT", adem√°s del monitoreo de variables ambientales c√≥mo la temperatura, gas CO2, h√∫medad.

<p align="center">
  <img src="images/EnsamblajePPS.JPG" alt="Vista del robot" width="500"/>
</p>

## üü†Tecnolog√≠as Aplicadas
‚Ä¢ ESP32 - Shield cnc 3 ejes, para el robot se utilizan motores nema 17 con reductor planetario 5:1, motores el√©ctricos de cc para el carro que lo traslada y sensores de proximidad FC.
‚Ä¢ Python - OpenCV, para el dise√±o de software de detecci√≥n y calculo de la cinem√°tica inversa.
‚Ä¢ Node-RED - MQTT, para el env√≠o y recepci√≥n de mensajes, aplicando los nodos se dise√±o un dashboard de control y monitoreo.
‚Ä¢ Sensores de CO‚ÇÇ MQ135, temperatura y humedad DHT11

## üü†Prototipo REAL

<p align="center">
  <img src="images/portada1.jpg" alt="Vista del robot" width="400"/>
  <img src="images/portada2.jpg" alt="Vista lateral" width="400"/>
</p>

## üü†Procesamiento de Im√°genes

Para la detecci√≥n autom√°tica de huevos se utiliza un modelo de visi√≥n por computadora entrenado en la plataforma Roboflow. El flujo de trabajo se resume en las siguientes etapas:

### Captura de imagen:
  La c√°mara ESP32-CAM ubicada en el extremos del codo apuntando hacia abajo captura las im√°genes en tiempo real enfocando el nido cubriendo toda la parte donde se ubica el huevo.
  La foto lo comprime en formato JPEG. Este archivo se transfiere a la PC. El resultado de este paso es un archivo ".jpg" accesible en el host.
### Inferencia con el modelo:
  Las im√°genes capturadas son enviadas al modelo de Roboflow, el cual aplica un algoritmo de detecci√≥n de objetos (YOLOv9). Como resultado, se obtiene un conjunto de predicciones que      incluyen:
  Clases detectadas (``huevo'').
  Confianza de detecci√≥n (probabilidad asociada a la predicci√≥n).
  Coordenadas del recuadro:
  (x, y, w, h) donde $x$ e $y$ representan la posici√≥n central del objeto, mientras que $w$ y $h$ corresponden al ancho y alto del recuadro.

### Conversi√≥n a coordenadas del robot:
  A partir de las coordenadas $(x, y)$ obtenidas de la imagen (resoluci√≥n de $640 \times 480$ p√≠xeles), se realiza una transformaci√≥n a coordenadas f√≠sicas reales del robot:
  (X_r, Y_r) = f(x, y)
  donde la funci√≥n $f$ corresponde a la calibraci√≥n que traduce los p√≠xeles en coordenadas cartesianas, garantizando que el brazo rob√≥tico pueda posicionarse correctamente sobre el        huevo.

  ‚Ä¢ Conversi√≥n de p√≠xeles a coordenadas f√≠sicas:

En el sistema de visi√≥n, las detecciones entregadas por el modelo de Roboflow
se expresan en coordenadas de imagen en p√≠xeles. Para utilizar estos
datos en el control del robot, es necesario transformarlos a coordenadas f√≠sicas
(X,Y) medidas en cent√≠metros sobre el plano de trabajo.

En una aproximaci√≥n simple, se realiza una calibraci√≥n lineal por
ejes independientes, donde se ajusta un factor de escala y un desplazamiento
(offset) a partir de puntos de referencia medidos experimentalmente:

$$
X = a_x \cdot u + b_x, \qquad
Y = a_y \cdot v + b_y
$$

donde:

  ‚Ä¢  \(u,v\): coordenadas en p√≠xeles de la detecci√≥n
  
  ‚Ä¢  \(X,Y\): coordenadas f√≠sicas en cm
  
  ‚Ä¢  \(a_x, a_y\): factores de conversi√≥n (cm/px)
  
  ‚Ä¢  \(b_x, b_y\): offsets de calibraci√≥n

En el prototipo actual se obtuvieron los siguientes valores:

$$
X = (0.0328)\cdot u + 0.5, \qquad
Y = (0.0327)\cdot v + 0.3
$$

### Selecci√≥n y validaci√≥n:
  Se consideran v√°lidas √∫nicamente las detecciones cuyo nivel de confianza sea mayor a un umbral predefinido $0.40$. 
    
### Env√≠o al sistema de control:
  Finalmente, con las coordenadas cartesianas corregidas $(X_r, Y_r)$ se calcula la cinem√°tica inversa por m√©todo geom√©trico del robot RRR para luego transmitir los angulos por el protocolo MQTT al controlador del robot para luego ejecutar la secuencia de agarre y recolecci√≥n.

  La salida del modelo Roboflow
  La predicci√≥n para un huevo detectado es el siguiente:
  "predictions": 
      "class": "egg",
      "confidence": 0.89,
      "x": 320,
      "y": 240,
      "width": 50,
      "height": 60
Este resultado indica que se detect√≥ un huevo con una confianza del $0.89$ en la posici√≥n $(320, 240)$. 

<p align="center">
  <img src="images/detecci√≥n.png" alt="Vista del robot" width="720"/>
</p>
<p align="center">
  <img src="images/coordenadas.png" alt="Vista del robot" width="1900"/>
</p>

## üü†Modelo matem√°tico (Cinem√°tica inversa) Robot

En los siguientes √≠tems se describe el modelo cinem√°tico inverso aplicado al robot de 3GDL por m√©todo geom√©trico.

 üîπ Articulaci√≥n de la base $$\(\theta_1)$$

Este √°ngulo se obtiene a partir de la proyecci√≥n del punto de acci√≥n sobre el plano XY.  
Las rotaciones se consideran respecto al eje Z.

$Coordenadas (px, py)$


$$
\theta_1 = 2\arctan\left(\frac{py}{px}\right)
$$

üîπ Articulaci√≥n del brazo $$\(\theta_2)$$

$$
A_1 = l_1 + l_2 \cos(\theta_3), \quad A_2 = l_2 \sin(\theta_3)
$$

La distancia proyectada sobre el plano XY es:

$$
d_p = p_x \cos(\theta_1) + p_y \sin(\theta_1)
$$

Relaciones trigonom√©tricas:

$$
\sin(\theta_2) = \frac{p'_z A_1 - d_p A_2}{A_1^2 + A_2^2}
$$

$$
\cos(\theta_2) = \frac{d_p A_1 - p'_z A_2}{A_1^2 + A_2^2}
$$

Finalmente:

$$
\theta_2 = 2\arctan\left(\frac{\sin(\theta_2)}{\cos(\theta_2)}\right)
$$

üîπ  Articulaci√≥n del codo $$\(\theta_3)$$

Se ajusta en el plano vertical de la base, considerando la distancia entre el gripper y el extremo del codo.  

Paso1. Se calcula la coordenada corregida en Z:

$$\ p'_z = p_z - b \$$



Paso2. Distancia proyectada:

$$\ D^2 = p_x^2 + p_y^2 + (p'_z)^2 \$$


Paso3. Aplicando la ley de cosenos:

$$\cos(\theta_3) = \frac{D^2 - l_1^2 - l_2^2}{2 l_1 l_2}\$$


Paso4. √Ångulo del codo:


$$\theta_3 = 2\arctan\left(\frac{\sqrt{1-\cos^2(\theta_3)}}{\cos(\theta_3)}\right)\$$


Configuraci√≥n **codo arriba**


‚Ä¢ Con estos tres coordenadas articulares $$\(\theta_1, \theta_2, \theta_3)\$$ se obtiene la **configuraci√≥n del robot** para alcanzar cualquier punto dentro de su espacio de trabajo 17x13cm.

## üü†Plano Electr√≥nico
Aqu√≠ una vista general del diagrama electr√≥nico principal del prototipo:

<p align="center">
  <img src="images/Esquematico1.jpg" alt="Vista" width="1200"/>
</p>
<p align="center">
  <img src="images/Esquematico2.jpg" alt="Vista" width="1200"/>
</p>

## üü†Planos Mec√°nicos
Aqu√≠ una vista general de los planos del prototipo:

<p align="center">
  <img src="images/1base_page-0001.jpg" alt="Vista del robot" width="400"/>
  <img src="images/5codoP1_page-0001.jpg" alt="Vista lateral" width="400"/>
</p>

## üü†Video del Prototipo en funcionamiento

[Link de Google Drive](https://drive.google.com/file/d/1ZrKL6yfj1HvtoRiwAzGiAirnJcBjSen1/view?usp=drive_link)

<p align="center">
  <img src="images/gif.gif" alt="Vista del robot" width="400"/>
</p>

## Agradecimiento

Quiero agradecer al profesor de la materia Proyecto Mecatr√≥nico LUKASZEWICZ, Cristian por su acompa√±amiento durante el desarrollo de este proyecto, el cual constituye una extensi√≥n del proyecto final de la carrera. La experiencia me permiti√≥ consolidar conocimientos en rob√≥tica, procesamiento de im√°genes, aplicaciones de softwares de dise√±o y programaci√≥n, para as√≠ aplicarlos de manera pr√°ctica, logrando resultados satisfactorios en la precisi√≥n del agarre del objeto gracias a la integraci√≥n de conceptos fundamentales que se requer√≠an. Este trabajo representa un paso importante en m√≠ proceso de constante aprendizaje, fortaleciendo las bases para seguir avanzando hacia las ciencias aplicadas y la construcci√≥n de nuevos desarrollos tecnol√≥gicos que me vaya proponiendo. Un fuerte agradecimiento a la FI-UNLZ por permitirme formarme en esta casa de estudios, brind√°ndome oportunidades de crecer en m√≠ formaci√≥n profesional.

<p align="center">
  <img src="images/Logo FIUNLZ.png" alt="Vista del robot" width="400"/>
</p>
